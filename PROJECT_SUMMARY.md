# Resumen del Proyecto: PiCar-X Feedback Loop

## ğŸ“‹ DescripciÃ³n

Sistema completo de **feedback loop** para el robot PiCar-X que integra:
- **VisiÃ³n** (screenshots, detecciÃ³n de objetos, caras, colores)
- **Audio** (reconocimiento de voz con Vosk STT)
- **Toma de decisiones** (motor de reglas o LLM)
- **Acciones del robot** (movimiento, cÃ¡mara, sensores)

## ğŸ¯ CaracterÃ­sticas Principales

### PercepciÃ³n Multi-Sensorial
- âœ… Captura de imÃ¡genes en tiempo real
- âœ… DetecciÃ³n de caras, colores, QR codes, gestos, seÃ±ales
- âœ… Reconocimiento de voz con Vosk
- âœ… Sensor ultrasÃ³nico para distancia
- âœ… Screenshots automÃ¡ticos

### Motores de DecisiÃ³n
- âœ… **Motor de Reglas**: RÃ¡pido, predecible, sin latencia
- âœ… **Motor LLM**: Inteligente, adaptativo, con razonamiento
- âœ… Sistema de prioridades configurable
- âœ… Reglas personalizables

### Control del Robot
- âœ… Movimiento (adelante, atrÃ¡s, giros)
- âœ… Control de cÃ¡mara (pan/tilt)
- âœ… Seguimiento suave de objetos
- âœ… Evitar obstÃ¡culos automÃ¡tico
- âœ… Text-to-Speech (TTS)
- âœ… Verificaciones de seguridad

### Modos de OperaciÃ³n
- âœ… AutÃ³nomo (sigue reglas)
- âœ… Control por voz
- âœ… Seguimiento de objetos
- âœ… ExploraciÃ³n libre

## ğŸ“ Estructura del Proyecto

```
picar-x-feedback-loop/
â”œâ”€â”€ README.md                    # DocumentaciÃ³n principal
â”œâ”€â”€ ARCHITECTURE.md              # Arquitectura detallada
â”œâ”€â”€ USAGE.md                     # GuÃ­a de uso
â”œâ”€â”€ PROJECT_SUMMARY.md           # Este archivo
â”œâ”€â”€ requirements.txt             # Dependencias Python
â”œâ”€â”€ install.sh                   # Script de instalaciÃ³n
â”œâ”€â”€ .gitignore
â”‚
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ settings.py              # ConfiguraciÃ³n central
â”‚   â””â”€â”€ secret.py.example        # Ejemplo de API keys
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ sensors/
â”‚   â”‚   â”œâ”€â”€ vision_sensor.py     # Captura y anÃ¡lisis de visiÃ³n
â”‚   â”‚   â””â”€â”€ audio_sensor.py      # Captura y anÃ¡lisis de audio
â”‚   â”‚
â”‚   â”œâ”€â”€ decision/
â”‚   â”‚   â”œâ”€â”€ rule_engine.py       # Motor de reglas
â”‚   â”‚   â””â”€â”€ llm_engine.py        # Motor con LLM
â”‚   â”‚
â”‚   â”œâ”€â”€ actions/
â”‚   â”‚   â””â”€â”€ robot_controller.py  # Control del robot
â”‚   â”‚
â”‚   â””â”€â”€ core/
â”‚       â””â”€â”€ feedback_loop.py     # Loop principal
â”‚
â””â”€â”€ examples/
    â”œâ”€â”€ basic_loop.py            # Ejemplo bÃ¡sico con reglas
    â”œâ”€â”€ advanced_loop.py         # Ejemplo con LLM
    â”œâ”€â”€ voice_control.py         # Control por voz
    â”œâ”€â”€ object_tracking.py       # Seguimiento de objetos
    â””â”€â”€ demo.py                  # Demo interactivo
```

## ğŸ”„ Ciclo de Feedback Loop

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FEEDBACK LOOP                        â”‚
â”‚                                                         â”‚
â”‚  1. PERCEPCIÃ“N                                         â”‚
â”‚     â”œâ”€ Capturar frame de cÃ¡mara                       â”‚
â”‚     â”œâ”€ Detectar objetos (caras, colores, etc.)       â”‚
â”‚     â”œâ”€ Escuchar audio (si estÃ¡ habilitado)           â”‚
â”‚     â””â”€ Leer sensor ultrasÃ³nico                        â”‚
â”‚                                                         â”‚
â”‚  2. CONSTRUCCIÃ“N DE CONTEXTO                          â”‚
â”‚     â””â”€ Convertir datos de sensores en contexto       â”‚
â”‚                                                         â”‚
â”‚  3. DECISIÃ“N                                           â”‚
â”‚     â”œâ”€ Evaluar reglas (o consultar LLM)              â”‚
â”‚     â””â”€ Determinar acciones a ejecutar                 â”‚
â”‚                                                         â”‚
â”‚  4. ACCIÃ“N                                             â”‚
â”‚     â”œâ”€ Ejecutar movimientos                           â”‚
â”‚     â”œâ”€ Ajustar cÃ¡mara                                 â”‚
â”‚     â””â”€ Reproducir sonidos/hablar                      â”‚
â”‚                                                         â”‚
â”‚  5. EVALUACIÃ“N                                         â”‚
â”‚     â”œâ”€ Verificar seguridad                            â”‚
â”‚     â””â”€ Ajustar comportamiento                         â”‚
â”‚                                                         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                   â”‚
â”‚                    â†“                                    â”‚
â”‚              (repetir a 10 Hz)                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Inicio RÃ¡pido

### InstalaciÃ³n

```bash
# En Raspberry Pi con PiCar-X
git clone <url-del-repo>
cd picar-x-feedback-loop
chmod +x install.sh
./install.sh
```

### Uso BÃ¡sico

```bash
# Ejemplo con reglas (sin LLM)
sudo python3 examples/basic_loop.py

# Control por voz
sudo python3 examples/voice_control.py

# Demo interactivo
sudo python3 examples/demo.py
```

### Uso Avanzado (con LLM)

```bash
# Configurar API key
cp config/secret.py.example config/secret.py
nano config/secret.py  # AÃ±adir OPENAI_API_KEY

# Ejecutar con LLM
sudo python3 examples/advanced_loop.py
```

## ğŸ® Ejemplos de Comportamiento

### 1. Seguimiento de Cara
```
Robot detecta cara â†’ Ajusta cÃ¡mara â†’ Se mueve hacia la cara â†’ Evita obstÃ¡culos
```

### 2. Seguimiento de Color
```
Robot detecta color rojo â†’ Centra objeto â†’ Se acerca â†’ Se detiene cerca
```

### 3. Evitar ObstÃ¡culos
```
Robot avanza â†’ Detecta obstÃ¡culo â†’ Se detiene â†’ Retrocede â†’ Gira â†’ ContinÃºa
```

### 4. Control por Voz
```
Usuario: "forward" â†’ Robot avanza 1 segundo â†’ Se detiene
Usuario: "follow me" â†’ Robot entra en modo seguimiento
```

### 5. ExploraciÃ³n AutÃ³noma
```
Robot explora â†’ Escanea entorno â†’ Evita obstÃ¡culos â†’ Reacciona a estÃ­mulos
```

## ğŸ”§ ConfiguraciÃ³n Clave

### Frecuencia del Loop
```python
LOOP_FREQUENCY = 10  # Hz (10 ciclos por segundo)
```

### Velocidades
```python
ROBOT_CONFIG = {
    'default_speed': 30,  # 0-100
    'slow_speed': 15,
    'fast_speed': 50,
}
```

### Reglas de Comportamiento
```python
BEHAVIOR_RULES = {
    'follow_face': {
        'priority': 0.9,
        'conditions': {'face_detected': True},
        'actions': ['track_face', 'move_forward_slow'],
    },
    # ... mÃ¡s reglas
}
```

### Comandos de Voz
```python
VOICE_COMMANDS = {
    'forward': ['forward', 'go forward', 'adelante'],
    'stop': ['stop', 'halt', 'para'],
    # ... mÃ¡s comandos
}
```

## ğŸ“Š MÃ©tricas y Rendimiento

### Rendimiento TÃ­pico
- **Frecuencia**: 10 Hz (100ms por ciclo)
- **Latencia de visiÃ³n**: ~30ms
- **Latencia de audio**: ~100ms (Vosk)
- **Latencia de LLM**: ~500-2000ms (depende del modelo)

### Optimizaciones
- Motor de reglas: Sin latencia de red
- Procesamiento asÃ­ncrono de audio
- CachÃ© de detecciones
- Throttling de llamadas a LLM

## ğŸ›¡ï¸ Seguridad

### Verificaciones AutomÃ¡ticas
- âœ… Distancia de emergencia (10cm)
- âœ… Tiempo mÃ¡ximo de movimiento continuo (5s)
- âœ… VerificaciÃ³n en cada ciclo del loop
- âœ… Prioridad mÃ¡xima para evitar obstÃ¡culos

### ConfiguraciÃ³n de Seguridad
```python
ROBOT_CONFIG = {
    'emergency_stop_distance': 10,  # cm
    'max_continuous_movement': 5.0,  # segundos
}
```

## ğŸ§ª Testing

### Modo SimulaciÃ³n
```python
# Para desarrollo sin hardware
PICARX_AVAILABLE = False
```

### Logs de Debug
```python
logging.basicConfig(level=logging.DEBUG)
```

## ğŸ“š DocumentaciÃ³n

- **README.md**: IntroducciÃ³n y caracterÃ­sticas
- **ARCHITECTURE.md**: Arquitectura detallada del sistema
- **USAGE.md**: GuÃ­a completa de uso
- **PROJECT_SUMMARY.md**: Este resumen

## ğŸ”® Extensiones Futuras

### Posibles Mejoras
- [ ] IntegraciÃ³n con mÃ¡s LLMs (Claude, Llama, etc.)
- [ ] Mapeo y navegaciÃ³n SLAM
- [ ] Reconocimiento de objetos con YOLO
- [ ] Control remoto vÃ­a web interface
- [ ] GrabaciÃ³n y replay de comportamientos
- [ ] Aprendizaje por refuerzo
- [ ] Multi-robot coordination

### PersonalizaciÃ³n
- AÃ±adir nuevos sensores (IMU, GPS, etc.)
- Crear nuevas reglas de comportamiento
- Integrar con servicios externos (APIs, bases de datos)
- Desarrollar comportamientos complejos

## ğŸ“ Notas TÃ©cnicas

### Dependencias Principales
- **robot-hat**: LibrerÃ­a de hardware del PiCar-X
- **picar-x**: API del robot
- **vilib**: LibrerÃ­a de visiÃ³n
- **vosk**: Speech-to-Text
- **openai**: API de OpenAI (opcional)
- **opencv-python**: Procesamiento de imÃ¡genes
- **pyaudio**: Captura de audio

### Requisitos del Sistema
- Raspberry Pi 4 (recomendado)
- PiCar-X completo con cÃ¡mara
- MicrÃ³fono USB o I2S
- ConexiÃ³n a internet (para LLM)

## ğŸ“ Conceptos Implementados

### RobÃ³tica
- Feedback loop
- Sensor fusion
- Reactive behavior
- Deliberative planning

### IA/ML
- Computer vision
- Speech recognition
- Natural language processing
- Rule-based systems
- LLM integration

### Software
- Modular architecture
- Event-driven programming
- Asynchronous processing
- Configuration management

## ğŸ“„ Licencia

GNU General Public License v2.0

## ğŸ‘¥ Contribuciones

Este proyecto estÃ¡ diseÃ±ado para ser extensible y educativo. SiÃ©ntete libre de:
- AÃ±adir nuevas funcionalidades
- Mejorar algoritmos existentes
- Crear nuevos ejemplos
- Reportar bugs
- Sugerir mejoras

---

**Desarrollado para PiCar-X v2.0**

*Sistema de feedback loop completo con visiÃ³n, audio y toma de decisiones inteligente*
